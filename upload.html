<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Face Upload & Verification Check</title>
<script defer src="./face-api.min.js"></script>

<style>
  body {
    font-family: Arial, sans-serif;
    background: #000;
    color: #0f0;
    margin: 0;
    padding: 0;
    display: flex;
    flex-direction: column;
    height: 100vh;
  }

  #videoContainer {
    flex: 1;
    display: flex;
    align-items: center;
    justify-content: center;
    padding: 10px;
  }

  video {
    width: 95%;
    height: auto;
    border: 2px solid #0f0;
    border-radius: 15px;
  }

  #bottomBar {
    padding: 15px;
    display: flex;
    justify-content: space-around;
    background: #111;
    border-top: 2px solid #0f0;
  }

  .btn {
    padding: 15px 25px;
    background: #0f0;
    color: #000;
    border: none;
    border-radius: 10px;
    font-size: 1.1em;
    font-weight: bold;
    cursor: pointer;
  }

  #log {
    padding: 10px;
    color: #0f0;
    text-align: center;
    font-size: 1em;
  }

  input[type=file] { display: none; }
</style>
</head>

<body>

<div id="videoContainer">
  <video id="video" autoplay playsinline></video>
</div>

<div id="log">Status: waiting...</div>

<div id="bottomBar">
  <button class="btn" id="snapBtn">Snap Photo</button>
  <button class="btn" id="uploadBtn">Upload Photo</button>
  <input type="file" id="fileInput" accept="image/*">
</div>

<script type="module">
import { db } from './firebaseConfig.js';
import { doc, setDoc } from 'https://www.gstatic.com/firebasejs/11.5.0/firebase-firestore.js';

const MODELS = "./models";
const studObj = JSON.parse(localStorage.getItem('currentUser'));

const video = document.getElementById('video');
const snapBtn = document.getElementById('snapBtn');
const uploadBtn = document.getElementById('uploadBtn');
const fileInput = document.getElementById('fileInput');
const logEl = document.getElementById('log');
const canvas = document.createElement("canvas");

function log(msg) {
  logEl.innerText = msg;
}

/* -------------------- LOAD FACE MODELS -------------------- */
async function loadModels() {
  log("Loading face detection models...");
  await Promise.all([
    faceapi.nets.tinyFaceDetector.loadFromUri(MODELS),
    faceapi.nets.faceLandmark68Net.loadFromUri(MODELS),
    faceapi.nets.faceRecognitionNet.loadFromUri(MODELS),
  ]);
  log("Models loaded ✔");
}

/* -------------------- CAMERA -------------------- */
async function startCamera() {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
    video.srcObject = stream;
  } catch (err) {
    log("Camera error: " + err);
  }
}

/* -------------------- FACE VALIDATION -------------------- */
async function detectFaceFromBlob(blob) {
  const img = await faceapi.bufferToImage(blob);

  const detection = await faceapi.detectAllFaces(img, new faceapi.TinyFaceDetectorOptions());

  if (detection.length === 0) {
    log("❌ No face detected. Try again.");
    return false;
  }
  if (detection.length > 1) {
    log("❌ Multiple faces detected. Only one face allowed.");
    return false;
  }

  log("✔ Face detected. Uploading...");
  return true;
}

/* -------------------- SNAP PHOTO FROM CAMERA -------------------- */
function snapPhoto() {
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;
  const ctx = canvas.getContext("2d");
  ctx.drawImage(video, 0, 0);

  canvas.toBlob(async (blob) => {
    const valid = await detectFaceFromBlob(blob);
    if (valid) compressAndUpload(blob);
  }, "image/jpeg", 0.7);
}

/* -------------------- COMPRESS -------------------- */
function compressImage(file, maxW = 800, maxH = 800, quality = 0.7) {
  return new Promise((resolve) => {
    const img = new Image();
    img.onload = () => {
      let { width, height } = img;
      if (width > maxW) { height = (maxW / width) * height; width = maxW; }
      if (height > maxH) { width = (maxH / height) * width; height = maxH; }

      canvas.width = width;
      canvas.height = height;
      canvas.getContext("2d").drawImage(img, 0, 0, width, height);

      canvas.toBlob((blob) => resolve(blob), "image/jpeg", quality);
    };
    img.src = URL.createObjectURL(file);
  });
}

/* -------------------- UPLOAD -------------------- */
async function uploadToCloudinary(blob) {
  const formData = new FormData();
  formData.append("file", blob);
  formData.append("upload_preset", "verifo");

  log("Uploading...");

  try {
    const res = await fetch("https://api.cloudinary.com/v1_1/dykvuhosr/image/upload", {
      method: "POST",
      body: formData
    });

    const data = await res.json();
    studObj.referencePic = data.secure_url;
    localStorage.setItem("currentUser", JSON.stringify(studObj));

    const reg = studObj.regNm.replace(/\//g, "-");
    const docRef = doc(db, "UNIUYO", studObj.level, studObj.dept, reg);

    await setDoc(docRef, { referencePic: data.secure_url }, { merge: true });

    log("✔ Upload successful!");
    window.location.href = "V3ADEX.html";
  } catch (err) {
    log("❌ Upload failed: " + err);
  }
}

/* compress + upload */
async function compressAndUpload(blobOrFile) {
  let blob = blobOrFile;
  if (!(blobOrFile instanceof Blob)) blob = await compressImage(blobOrFile);

  if (await detectFaceFromBlob(blob)) {
    uploadToCloudinary(blob);
  }
}

/* -------------------- EVENTS -------------------- */
snapBtn.onclick = snapPhoto;

uploadBtn.onclick = () => fileInput.click();

fileInput.onchange = async () => {
  const file = fileInput.files[0];
  const blob = await compressImage(file);

  if (await detectFaceFromBlob(blob)) {
    uploadToCloudinary(blob);
  }
};

/* INIT */
await loadModels();
startCamera();

</script>

</body>
</html>
